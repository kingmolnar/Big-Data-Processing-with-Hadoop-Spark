{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Yelp Reviews\n",
    "Let's explore the Yelp reviews and perform a sentiment analysis:\n",
    "\n",
    "1. Load reviews from data file ... there are in JSON format\n",
    "2. Convert JSON records to Python tuples for earch row, extract only what we need\n",
    "3. Maybe Look at stars rating\n",
    "4. Create list of words (or bag-of-words)\n",
    "4. Load sentiment dictionary file and convert into a useful format.\n",
    "5. Assign sentiment values (pos and neg) to words of reviews\n",
    "6. Aggregate over reviews and report sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T10:32:17.853385",
     "start_time": "2017-10-21T10:23:41.778635"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched Spark version 1.6.1 with ID application_1508160140652_0054\n",
      "http://arc.insight.gsu.edu:8088/cluster/app/application_1508160140652_0054\n"
     ]
    }
   ],
   "source": [
    "# %load pyspark_init_arc.py\n",
    "#\n",
    "# This configuration works for Spark on macOS using homebrew\n",
    "#\n",
    "import os, sys\n",
    "# set OS environment variable\n",
    "os.environ[\"SPARK_HOME\"] = '/usr/hdp/2.4.2.0-258/spark'\n",
    "# add Spark library to Python\n",
    "sys.path.insert(0, os.path.join(os.environ[\"SPARK_HOME\"], 'python'))\n",
    "\n",
    "# import package\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "\n",
    "import atexit\n",
    "def stop_my_spark():\n",
    "    sc.stop()\n",
    "    del(sc)\n",
    "\n",
    "# Register exit    \n",
    "atexit.register(stop_my_spark)\n",
    "\n",
    "# Configure and start Spark ... but only once.\n",
    "if not 'sc' in globals():\n",
    "    conf = SparkConf()\n",
    "    conf.setAppName('SentimentAnalysis') ## you may want to change this\n",
    "    conf.setMaster('yarn-client')\n",
    "    conf.set('spark.ui.port', '63340')\n",
    "    sc = SparkContext(conf=conf)\n",
    "    print \"Launched Spark version %s with ID %s\" % (sc.version, sc.applicationId)\n",
    "    print \"http://arc.insight.gsu.edu:8088/cluster/app/%s\"% (sc.applicationId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T10:47:26.028213",
     "start_time": "2017-10-20T10:47:26.008575"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"http://arc.insight.gsu.edu:8088/cluster/app/%s\"% (sc.applicationId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T10:03:42.211802",
     "start_time": "2017-10-21T10:03:36.910536"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "hdfs dfs -ls /data/yelp/review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T10:03:30.151281",
     "start_time": "2017-10-21T10:03:30.145834"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR='/data/yelp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T15:58:21.077296",
     "start_time": "2017-10-20T15:58:20.341851"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_rdd = sc.textFile(os.path.join(DATADIR, 'review/review_ab.json.gz')).sample(False, 0.01, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Glance at Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T15:58:56.870445",
     "start_time": "2017-10-20T15:58:54.332784"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T15:59:17.660561",
     "start_time": "2017-10-20T15:59:15.407459"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-11T11:20:45.629821",
     "start_time": "2017-02-11T11:20:39.731053"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many elements do we actually have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T10:49:53.815773",
     "start_time": "2017-10-20T10:49:53.812385"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text =  \"Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T10:49:49.669606",
     "start_time": "2017-10-20T10:49:49.645919"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text2words(text):\n",
    "    import re\n",
    "    def clean_text(text):\n",
    "        return re.sub(r'[.;:,!\\'\"]', ' ', unicode(text).lower())\n",
    "    return filter(lambda x: x!='', clean_text(text).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T10:50:03.322325",
     "start_time": "2017-10-20T10:50:03.316979"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text2words(text)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T10:06:39.033068",
     "start_time": "2017-10-21T10:06:39.028938"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def json_review(s):\n",
    "    import json\n",
    "    r = json.loads(s.strip())\n",
    "    return (r['business_id']+'^'+r['review_id'], r['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T10:09:27.358501",
     "start_time": "2017-10-21T10:09:27.350185"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "js = u'{\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"pGxyI2QhPpyn3RT61sbfXQ\", \"review_id\": \"rNExnQ7fMtXajA4Xx57BTg\", \"stars\": 5, \"date\": \"2016-03-23\", \"text\": \"This is my first time ever writing a review. But Martha is such a great doctor I thought I should share what I know.\\\\n\\\\nAa a scared pregnant teenager i met Martha for the first time 17 years old. 20 years later I am still a patient of Martha\\'s. This is one of those rare doctors that I have met that actually care about her patients well-being. It\\'s treacherous having to go to the doctor so often. When I walk in the office it\\'s comfortable and I know I am in good hands. This makes all the difference and I am not kept waiting all day.\\\\n \\\\nI encourage every Woman to have a personal relationship with their doctor. Alternative for women is a great place to try. Once you go you will understand the importance of a excellent doctor and a great staff. I love Martha. Not only did she see me through the birth of my big healthy baby. She is still seeing me through all my health problems and making it alot easier on me in the process. Check her out.\", \"type\": \"review\", \"business_id\": \"se11kpNHxkw59O_7wwWhaQ\"}'\n",
    "#print js\n",
    "import json\n",
    "print json.loads(js).keys()\n",
    "jsdict = json.loads(js)\n",
    "for k in jsdict.keys():\n",
    "    print k, jsdict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:46:37.915444",
     "start_time": "2017-10-20T11:46:37.805759"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OK, let's create a `review_rdd` with only the elements we care bout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:46:50.539169",
     "start_time": "2017-10-20T11:46:50.535146"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# next thing create a word list `words_rdd`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:46:52.491668",
     "start_time": "2017-10-20T11:46:52.413695"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T10:13:40.393509",
     "start_time": "2017-10-21T10:13:34.904001"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "hdfs dfs -cat /data/yelp/SentiWordNet_3.0.0_20130122.txt | head -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T10:55:14.751886",
     "start_time": "2017-10-20T10:55:14.285396"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentidict = sc.textFile(os.path.join(DATADIR, 'SentiWordNet_3.0.0_20130122.txt'))\n",
    "print sentidict.count()\n",
    "sentidict.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:04:28.458625",
     "start_time": "2017-10-20T11:04:28.454671"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_senti_words(x):\n",
    "    xl = x.split(' ')\n",
    "    return map(lambda r: r.split('#')[0], xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:04:30.235045",
     "start_time": "2017-10-20T11:04:30.230184"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_senti_words(u'dorsal#2 abaxial#1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:16:05.628664",
     "start_time": "2017-10-20T11:16:05.620706"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_senti_recs(s):\n",
    "    try:\n",
    "        sl = s.split('\\t')\n",
    "        pos = sl[0]\n",
    "        wid = sl[1]\n",
    "        pos = sl[2]\n",
    "        neg = sl[3]\n",
    "        wrds = split_senti_words(sl[4])\n",
    "        return [(w, (float(pos), float(neg))) for w in wrds]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:16:07.826476",
     "start_time": "2017-10-20T11:16:07.733826"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now let's create a dictionary that we can join to the word list `sdict_rdd`\n",
    "# What are we going to do with the synonyms in the dictionary?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:47:16.560179",
     "start_time": "2017-10-20T11:47:13.525201"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's join and create a `jnt_rdd`\n",
    "# Hint: the joining key is the first element in the tuple\n",
    "\n",
    "\n",
    "\n",
    "jnt_rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T11:47:34.239596",
     "start_time": "2017-10-20T11:47:32.401602"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# OK, after joining add up the positive and negative scores, create `res_rdd`\n",
    "# Hint: use reduceByKey\n",
    "\n",
    "\n",
    "res_rdd.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics\n",
    "\n",
    "Using short cut calculation:\n",
    "\n",
    "$$mean = \\frac{1}{n} \\sum_{i=1}^n x_i$$\n",
    "\n",
    "$$var = \\frac{1}{n-1}( \\sum_{i=1}^n x_i^2 - \\frac{ (\\sum_{i=1}^n x_i)^2}{n})$$\n",
    "\n",
    "\n",
    "Suggestion https://stackoverflow.com/questions/39981312/spark-rdd-how-to-calculate-statistics-most-efficiently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try reduceByKey. It's pretty straightforward if we only want to compute the min():\n",
    "\n",
    "    rdd.reduceByKey(lambda x,y: min(x,y)).collect()\n",
    "#Out[84]: [('key3', 2.0), ('key2', 3.0), ('key1', 1.0)]\n",
    "To calculate the mean, you'll first need to create (value, 1) tuples which we use to calculate both the sum and count in the reduceByKey operation. Lastly we divide them by each other to arrive at the mean:\n",
    "\n",
    "    meanRDD = (rdd\n",
    "               .mapValues(lambda x: (x, 1))\n",
    "               .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "               .mapValues(lambda x: x[0]/x[1]))\n",
    "\n",
    "    meanRDD.collect()\n",
    "#Out[85]: [('key3', 5.5), ('key2', 5.0), ('key1', 3.3333333333333335)]\n",
    "For the variance, you can use the formula (sumOfSquares/count) - (sum/count)^2, which we translate in the following way:\n",
    "\n",
    "    varRDD = (rdd\n",
    "              .mapValues(lambda x: (1, x, x*x))\n",
    "              .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1], x[2]+y[2]))\n",
    "              .mapValues(lambda x: (x[2]/x[0] - (x[1]/x[0])**2)))\n",
    "\n",
    "    varRDD.collect()\n",
    "#Out[106]: [('key3', 12.25), ('key2', 4.0), ('key1', 2.8888888888888875)]\n",
    "I used values of type double instead of int in the dummy data to accurately illustrate computing the average and variance:\n",
    "\n",
    "    rdd = sc.parallelize([(\"key1\", 1.0),\n",
    "                          (\"key3\", 9.0),\n",
    "                          (\"key2\", 3.0),\n",
    "                          (\"key1\", 4.0),\n",
    "                          (\"key1\", 5.0),\n",
    "                          (\"key3\", 2.0),\n",
    "                          (\"key2\", 7.0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T12:28:08.301949",
     "start_time": "2017-10-20T12:28:08.190580"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We need to create a dataset to produce N=number of samples, mean(pos), var(pos), mean(neg), var(neg)\n",
    "# once we have that in place we can aggregate\n",
    "# Note: we are instested in mean and var per business...\n",
    "\n",
    "\n",
    "res2_rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T12:03:57.081986",
     "start_time": "2017-10-20T12:03:56.865289"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now aggreate \n",
    "res2_rdd.reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1], a[2]+b[2], a[3]+b[4], a[1]+b[4])).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
